# PredicTalk
<img src="https://github.com/jphacks/NG_2305/assets/78719395/728ca450-a66f-488c-b3fd-08c311537cdf" width=300>

## 製品概要
初心者以上・ネイティブ未満の外国語学習者の会話を視覚的に補助するためのアプリ

### 背景(製品開発のきっかけ、課題等）
外国語の会話を難しくする問題点はいくつかある．  
その1つとして「基本的な単語や文法は知っていても，実際の会話でスムーズに単語や文法が浮かんでこない」という点が挙げられる．  
この問題の1つの解決方法として，自分の言いたいことを翻訳アプリに通して出力された文章を発音するという方法が考えられる．  
しかしこの方法では
- 「自分の力で会話しているとは言い難く，相手とコミュニケーションしている実感が得られない」
- 「スムーズな会話ができない」
- 「基本的な語学知識はあるのに翻訳アプリに頼りきりなのはもどかしい」
といった様々なデメリットが生まれる．
  
実際，チームメンバーである青原・伊藤・目瀬の3人は今年の3月に1カ月間フランスへ留学した際，このようなジレンマを何度も経験した．  
そこで今回はこの問題を解決するために，「初心者以上・ネイティブ未満の外国語学習者の会話を視覚的に補助するアプリ」の技術開発に取り組むことにした．  

### 製品説明（具体的な製品の説明）
このアプリはスマホ専用（現在はiOSのみ対応）である．  
アプリのみでも機能するが，実際には市販のARグラスを利用することを想定している．  
ARグラスを利用している場合における，製品の流れは以下のとおりである．  
1. アプリを起動して画面をタップすると音声認識が開始される．
2. 自分が発話するとその発話が音声認識され，次に予想される単語がARグラス表示される．
3. ユーザはARグラスに表示された単語を見ることで，思い出せなかった単語や文法を思い出すことで発話をスムーズに行うことができる．

### 特長
#### 1. 特長1：発話を補助しすぎない点
「背景」の項で説明した通り，外国語の発話をスムーズに行うことのみを解決するのであれば，自分の言いたいことを翻訳アプリに通して出てきた文章を発音すればよい．  
しかし実際には，「基本的な語学知識を持っているので，できる限り外国の人と自分の力でコミュニケーションをしたい」というニーズがある．  
これまで勉強してきた単語や文法を駆使して相手と同じ言語でやり取りできる喜びは，翻訳アプリに頼っていては得られないものである．  
今回はこのニーズに応えるために，基本的な単語や文法を知っている外国語学習者を対象に，発話における最低限の補助をすることを1つ目の特徴として製品開発に取り組んだ．

#### 2. 特長2：発話を視覚的に補助する点
コミュニケーションにおいて大切と考えられることの1つに，相手の表情や仕草を見ることが挙げられる．  
そのため，我々は相手を見ながら発話の補助をする必要があると考えている．  
その上で，相手を見ながら発話の補助をできる，すなわち発話を視覚的に補助するデバイスとしてARグラスを使用することを2つ目の特徴としている．  
コミュニケーション中にARグラスへ予測単語を反映するという取り組みは，本製品における新しい試みと考えられる．

#### 3. 特長3：既存の技術を上手に活用して速度と精度を両立している点
本製品においてボトルネックは2か所存在する．  
1つ目は音声認識の部分である．  
この部分はAppleのSpeach frameworkを利用することで速度と精度が担保されている．  
2つ目は認識した発話から単語や文法を予測する部分である．  
これまでの製品では比較的精度の高い単語予測を実現するために単語埋め込み・RNN・CNN・Attentionなどが利用されてきた．  
今回の製品では，現在我々が利用できる単語予測技術(MoblieBert，GPT2等）を複数試行した結果，精度と速度のバランスが最も良い事前学習済みの大規模言語モデルGPT3.5-TurboのAPIを利用することにした．


### 解決出来ること
まず「背景」の項で説明した,初心者以上・ネイティブ未満の外国語学習者が持っている「学んだ外国語を利用してコミュニケーションしたい」けど「実際の会話で単語や文法がスムーズに出てこない」でも「せっかく勉強したのに翻訳アプリにすべて頼って会話するのはもったいない」

というジレンマを解決できる．
  
また，ただ単語予測をスマホ画面に表示して補助するのではなく市販のARグラスに投影する形で表示することで
- 相手とのスムーズなコミュニケーションを妨げることなく発話の補助をする
  
ことを達成している．

### 今後の展望
今後の展望としては2つの改善点が挙げられる．  
  
1つ目は，対話内容に基づく予測単語の精度向上である．  
スマホやPCの文字入力では自身の入力履歴に基づき，予測単語の精度が向上する．  
本製品もこの技術の考え方を利用して，現在の対話内容や過去の対話履歴に基づき予測精度を向上することを考えている．
  
2つ目は，予測速度の向上である．  
本製品において予測単語を表示する速度は，製品のクオリティに直結する重要な要素である．  
今回は時間の都合上，予測単語を取得するためのモデルとしてMoblieBertとGPT2の2つしか試行することができなかった．  
しかし，これら2つ以外の単語予測モデルとしてGPT3やLLaMA等が存在する．  
さらに，今後もより大量の学習データによって生成された大規模言語モデルが登場することが予想される．  
本製品の速度向上のためには，このような様々なモデルを組み込んで試行する必要がある．  

### 注力したこと（こだわり等）
- モデルの選択と実装.既存の音声認識技術・単語予測技術を複数試行して，本製品にとって速度と精度がバランスよく両立できるようなモデルを選び，アプリに実装している
- 新たな情報源の導入.市販のARデバイスで使用できることで，本製品の目的であるコミュニケーションのスムーズさを妨害しないで発話の補助を達成している
- 視覚的に邪魔になる情報の削除.タップの判定エリアを画面全体にすることで、文章に集中できる.さらに、話しながらのタップも可能となっている.その他、home bar以外は全て削除している.

## 開発技術
### 活用した技術
#### API・データ
- GPT3.5-Turbo API

#### フレームワーク・ライブラリ・モジュール
- Apple Speach framework
- Moya

#### デバイス
- XREAL air

### 独自技術
#### ハッカソンで開発した独自機能・技術
* 独自で開発したものの内容をこちらに記載してください
* 特に力を入れた部分をファイルリンク、またはcommit_idを記載してください。

#### 製品に取り入れた研究内容（データ・ソフトウェアなど）（※アカデミック部門の場合のみ提出必須）
アカデミック部門ではないため無し



